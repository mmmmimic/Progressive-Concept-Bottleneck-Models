import torch
import torch.nn as nn
import numpy as np
from ._modules import DenseLayer

class Predictor(nn.Module):
    '''
    Linear Probe

    Conceiver -> Predictor
    c -> y
    '''
    def __init__(
                self, 
                num_classes, # number of categories
                concept_num, # number of property concepts
                expand_dim=256, # latent dimension of the Predictor (c -> y)
                head_num=16, # number of new concepts generated by concept interaction
                cat_index=[], # the indices of binary concepts, which would be used for concept interaction 
                ):
        super().__init__()
        if head_num:
            # if not 0, activate concept interaction
            cat_concept_num = len(cat_index)
            assert cat_concept_num > 0,'When concept interaction is activated, property concepts should include caterogical concepts'
            self.cat_index = cat_index

            # DenseLayer is a block of linear layer, batch norm and leakyrelu
            self.grouping = nn.Sequential(
                DenseLayer(cat_concept_num, 32),
                DenseLayer(32, 64),
                DenseLayer(64, head_num*cat_concept_num)
            )
        self.head_num = head_num

        if expand_dim:
            # if not 0, then a 2 layer mlp, otherwise a linear layer
            self.fc = nn.Sequential(
                            DenseLayer((concept_num+head_num), expand_dim, bn=False),
                            DenseLayer(expand_dim, num_classes, activation=None, bn=False)
                            )
        else:
            # if 0, linear probe
            self.fc = DenseLayer(concept_num+head_num, num_classes, activation=None, bn=False)
        self.expand_dim = expand_dim

        self.concept_num = concept_num

    def forward(self, x):
        '''
        x should include
        ['concept_logit']
        '''
        concept_logit = x['concept_logit']
        
        # Predictor (c -> y)
        if self.head_num:
            raw_concept = concept_logit.detach().clone()
            cat_concept = concept_logit[:,self.cat_index]
            square_concept = cat_concept**2

            groups = self.grouping(cat_concept)
            groups = nn.functional.relu(groups.reshape(cat_concept.size(0), self.head_num, -1))

            cat_concept = cat_concept.unsqueeze(-1)
            groups = groups.expand(cat_concept.size(0), self.head_num, square_concept.shape[-1])
            interacted_concept = (groups@cat_concept).flatten(-2) # B, H, G, 1

            # group squared concepts
            square_concept = square_concept.unsqueeze(-1)
            square_concept = (groups**2@square_concept).flatten(-2)
            interacted_concept = (interacted_concept**2 - square_concept) / 2 # (x1+x2)**2 - x1**2 - x2**2
            # (a+b)
            norminal = (groups.sum(-1))**2
            # (a2+b2)
            square_norm = (groups**2).sum(-1)
            norm = (norminal - square_norm)/2

            norm = torch.clamp(norm, min=1e-9)
            interacted_concept = interacted_concept / norm
            interacted_concept = torch.relu(interacted_concept)
            interacted_concept = torch.sqrt(interacted_concept)
            enhanced_concept = torch.cat((raw_concept, interacted_concept), dim=-1)
            x['interaction_weight'] = groups

        else:
            enhanced_concept = concept_logit

        logit = self.fc(enhanced_concept)
        
        x['logit'] = logit
        x['enhanced_concept'] = enhanced_concept

        return x   


if __name__ == "__main__":
    model = Predictor(num_classes=8, concept_num=27, expand_dim=256, head_num=16, cat_index=[2, 3, 4, 8, 13, 17, 22, 24])
    concept_logit = torch.rand(2, 27)
    x = model({'concept_logit':concept_logit})
    print(x['logit'].shape)
    print(x['enhanced_concept'].shape)
    print(x['interaction_weight'][0,1,:])

